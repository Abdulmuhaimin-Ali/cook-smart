```markdown
## Purpose & Overview

This `src/services/chatgpt.ts` file defines a service, `ChatGPTService`, responsible for interacting with the OpenAI ChatGPT API. It encapsulates the logic for authenticating, sending requests, and handling responses from the API. The service provides a simple and convenient way to integrate ChatGPT functionality into an application. It also stores the API key securely (using `localStorage`) and provides methods to manage it. Access to the service is provided through a singleton instance, ensuring consistent configuration and usage.

## Key Functions/Components

*   **`ChatCompletionMessage` Interface:** Defines the structure of a message used in the chat completion request.  It specifies the `role` (system, user, or assistant) and the `content` of the message.

*   **`ChatCompletionOptions` Interface:** Defines the structure for the options to be passed in the chat completion request, eg. `model`, `messages`, `temperature`, and `max_tokens`.

*   **`ChatCompletionResponse` Interface:** Defines the structure of the response received from the ChatGPT API. This includes the `id`, `object`, `created`, `model`, `choices`, and `usage` properties.

*   **`ChatGPTService` Class:**
    *   `apiKey: string`: Stores the API key retrieved from `localStorage`.
    *   `apiEndpoint: string`:  Defines the endpoint of the OpenAI ChatGPT API.
    *   `saveApiKey(key: string): void`: Saves the provided API key to `localStorage` and updates the `apiKey` property.
    *   `isConfigured(): boolean`: Checks if an API key is configured (present in `localStorage`).
    *   `getApiKey(): string`: Returns the currently configured API key.
    *   `createChatCompletion(options: ChatCompletionOptions): Promise<ChatCompletionResponse>`: Sends a request to the ChatGPT API with the provided options and returns a `Promise` that resolves to the API response.  Handles API key validation and error handling.

*   **`chatGPTService` (Singleton Instance):** A single instance of the `ChatGPTService` class, exported for use throughout the application. This ensures a single point of configuration for the API key.

## Business Logic (if applicable)

*   **API Key Management:** The service securely stores and retrieves the API key from `localStorage`. This allows the application to persist the API key between sessions.
*   **Configuration Check:**  The `isConfigured()` method allows the application to check if the API key is configured before making API requests.
*   **Request Handling:** The `createChatCompletion()` method handles the construction of the API request, including setting the necessary headers (Content-Type and Authorization), and stringifying the request body.
*   **Error Handling:** The `createChatCompletion()` method handles potential errors during the API request, such as network errors or invalid API keys. It parses the error response and throws an error with a descriptive message.
*   **Default values:** The `createChatCompletion()` function configures a default `temperature` of `0.7` and a default `max_tokens` of `1000` to ensure reasonable and contained usage.

## Input/Output Specifications

**`ChatCompletionMessage` Interface:**

*   **Input:**
    *   `role`: `"system" | "user" | "assistant"` - Categorizes who sent the message: the system, the user, or the assistant.
    *   `content`: `string` - The text content of the message.
*   **Output:**  Represents a structured message object suitable for the ChatGPT API.

**`ChatCompletionOptions` Interface:**

*   **Input:**
    *   `model`: `string` - The name of the ChatGPT model to use (e.g., "gpt-3.5-turbo").
    *   `messages`: `ChatCompletionMessage[]` - An array of messages representing the conversation history.
    *   `temperature?`: `number` (optional) - A value between 0 and 2 representing the randomness of the response. Defaults to 0.7 in the implementation.
    *   `max_tokens?`: `number` (optional) - The maximum number of tokens to generate in the response. Defaults to 1000 in the implementation.
*   **Output:** Represents a structured options object suitable for the ChatGPT API.

**`ChatCompletionResponse` Interface:**

*   **Input:**  The raw JSON response from the OpenAI ChatGPT API.
*   **Output:**
    *   `id`: `string` - The unique ID of the completion.
    *   `object`: `string` - The type of object (e.g., "chat.completion").
    *   `created`: `number` - The timestamp of when the completion was created.
    *   `model`: `string` - The model used for the completion.
    *   `choices`: `{ index: number; message: ChatCompletionMessage; finish_reason: string; }[]` - An array of possible completion choices.
        *   `index`: Represents the sequence number of the choice.
        *   `message`: The completed message generated by the model.
        *   `finish_reason`: The reason the completion stopped (e.g., "stop" or "length").
    *   `usage`: `{ prompt_tokens: number; completion_tokens: number; total_tokens: number; }` - Usage statistics for the completion.
        *   `prompt_tokens`: The number of tokens used in the prompt.
        *   `completion_tokens`: The number of tokens used in the completion.
        *   `total_tokens`: The total number of tokens used (prompt + completion).

**`ChatGPTService.createChatCompletion(options: ChatCompletionOptions)`:**

*   **Input:** `ChatCompletionOptions`
*   **Output:** `Promise<ChatCompletionResponse>` - A promise that resolves with the `ChatCompletionResponse` object, or rejects with an error message.

## Usage Examples

```typescript
import { chatGPTService, ChatCompletionMessage } from "./services/chatgpt";

async function getChatGPTResponse(prompt: string) {
  if (!chatGPTService.isConfigured()) {
    console.error("ChatGPT API key is not configured.");
    return;
  }

  const messages: ChatCompletionMessage[] = [
    { role: "user", content: prompt },
  ];

  try {
    const response = await chatGPTService.createChatCompletion({
      model: "gpt-3.5-turbo",
      messages: messages,
      temperature: 0.8,
    });

    console.log("ChatGPT Response:", response.choices[0].message.content);
  } catch (error: any) {
    console.error("Error getting ChatGPT response:", error.message);
  }
}

// Example Usage:
getChatGPTResponse("What is the capital of France?");

// Set the API key:
chatGPTService.saveApiKey("YOUR_ACTUAL_API_KEY");

// Get the API Key:
const apiKey = chatGPTService.getApiKey();
console.log(`API Key = ${apiKey}`);
```

## Dependencies

*   **`localStorage`:** Used for storing the API key. This is a browser API and this code may require modification for use outside of a browser environment.
*   **`fetch`:** Used for making HTTP requests to the ChatGPT API. This is a browser API and this code may require modification for use outside of a browser environment.

## Important Notes

*   **API Key Security:** While `localStorage` is used to store the API key, it's important to remember that it's not a completely secure solution, especially in client-side applications. Consider server-side implementation or more robust methods such as environment variables for increased security.
*   **Error Handling:** The code includes basic error handling for API requests.  Implement more robust error handling strategies, such as retry mechanisms or logging, to ensure the application gracefully handles potential errors.
*   **Rate Limiting:** Be mindful of the OpenAI API rate limits. Implement strategies to avoid exceeding the rate limits, such as caching responses or using a queue for API requests.
*   **Cost Management:**  Monitor your OpenAI API usage to avoid unexpected charges. Regularly review your billing and usage statistics to stay within your budget.
*   **Browser Compatibility:**  Ensure that the code is compatible with the target browsers. `localStorage` and `fetch` are widely supported, but consider using polyfills for older browsers.
*   **Environment Considerations:** If using outside of a browser, replace `localStorage` and `fetch` with appropriate environment-specific equivalents.
*   **Typescript Warnings:** Ensure that your typescript configuration allows for `localStorage` and `fetch` and that all types are accurately configured.
